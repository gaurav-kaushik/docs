{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGC API Quickstart\n",
    "This Guide leads you through a simple RNA sequencing analysis which parallels the GUI Quickstart using the CGC API. We have written this example in Python, but the concepts can be adapted to your preferred programming language. We encourage you to try this analysis yourself \n",
    "\n",
    "## Set project name, application, and AUTH_TOKEN\n",
    "In the code below, please replace the AUTH_TOKEN string with your authentication token string! Otherwise the code wil only mock you. The authentication token associated with your account, which you can get by going to [Developer Dashboard](https://cgc.sbgenomics.com/account/#developer) after logging into your account.  Remember to **keep your AUTH_TOKEN secure!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  IMPORTS\n",
    "import time as timer\n",
    "from requests import request\n",
    "import json\n",
    "from urllib2 import urlopen\n",
    "import os\n",
    "\n",
    "\n",
    "#  GLOBALS\n",
    "FLAGS = {'targetFound': False,                          # target project exists in CGC project\n",
    "         'taskRunning': False,                          # task is still running\n",
    "         'startTasks': True                             # (False) create, but do NOT start tasks\n",
    "        }\n",
    "TARGET_PROJECT = 'Quickstart_API'                       # project we will create in CGC (Settings > Project name in GUI)\n",
    "TARGET_APP = 'RNA-seq Alignment - STAR for TCGA PE tar' # app to use\n",
    "INPUT_EXT = 'tar.gz'\n",
    "\n",
    "AUTH_TOKEN = 'AUTH_TOKEN'                               # TODO: replace 'AUTH_TOKEN' with yours here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions & Classes\n",
    "Since we are going to write the functions that interact with API in Python, we'll prepare a function that converts the information we send and receive into JSON. \n",
    "We will not only create things but also need to interact with them, so in this demo we also may use object oriented programming. The class definition is below. Generally, the api_calls will either return a **list of things** (e.g. *myFiles is plural*) or a very **detailed description of one thing** (e.g. *myFile is singular*). The appropriate structure is created automatically in the response_to_fields() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  FUNCTIONS\n",
    "def api_call(path, method='GET', query=None, data=None, flagFullPath=False):\n",
    "    \"\"\" Translates all the HTTP calls to interface with the CGC\n",
    "\n",
    "    code adapted from the Seven Bridges platform API example\n",
    "    https://docs.sbgenomics.com/display/developerhub/Quickstart\n",
    "    flagFullPath is novel, added to smoothly resolve API pagination issues\"\"\"\n",
    "    data = json.dumps(data) if isinstance(data, dict) or isinstance(data,list)  else None\n",
    "    base_url = 'https://cgc-api.sbgenomics.com/v2/'\n",
    "\n",
    "    headers = {\n",
    "        'X-SBG-Auth-Token': AUTH_TOKEN,\n",
    "        'Accept': 'application/json',\n",
    "        'Content-type': 'application/json',\n",
    "    }\n",
    "\n",
    "    if flagFullPath:\n",
    "        response = request(method, path, params=query, data=data, headers=headers)\n",
    "    else:\n",
    "        response = request(method, base_url + path, params=query, data=data, headers=headers)\n",
    "    response_dict = json.loads(response.content) if response.content else {}\n",
    "\n",
    "    if response.status_code / 100 != 2:\n",
    "        print response_dict['message']\n",
    "        raise Exception('Server responded with status code %s.' % response.status_code)\n",
    "    return response_dict\n",
    "\n",
    "def print_project_details(proj, flag_new):\n",
    "    #Output details of the project\n",
    "    if flag_new:\n",
    "        print \"Congratulations, you have made a new project. Details: \\n\"\n",
    "    else:\n",
    "        print \"Your project exists. Details: \\n\"\n",
    "\n",
    "    print u'\\u2022' + (\"Name: %s \\n\") % (proj.name)\n",
    "    print u'\\u2022' + (\"ID: %s \\n\") % (proj.id)\n",
    "    print u'\\u2022' + (\"Description: %s \\n\") % (proj.description)\n",
    "    return None\n",
    "\n",
    "def download_files(fileList):\n",
    "    # download a list of files from URLs (adapted from a few stackoverflow threads)\n",
    "    dl_dir = 'files/downloads/'\n",
    "    try:                    # make sure we have the download directory\n",
    "        os.stat(dl_dir)\n",
    "    except:\n",
    "        hello()\n",
    "        a = dl_dir.split('/')[:-1]\n",
    "        b = ''\n",
    "        for a_dir in a:\n",
    "            b = b + a_dir\n",
    "            os.mkdir(b)\n",
    "            b = b + '/'\n",
    "        del a, b, a_dir\n",
    "\n",
    "    for ii in range(1, len(fileList)):  # skip first [0] entry, it is a text header\n",
    "        url = fileList[ii]\n",
    "        file_name = url.split('/')[-1]\n",
    "        file_name = file_name.split('?')[0]\n",
    "        file_name = file_name.split('%2B')[1]\n",
    "        u = urlopen(url)\n",
    "        f = open((dl_dir + file_name), 'wb')\n",
    "        meta = u.info()\n",
    "        file_size = int(meta.getheaders(\"Content-Length\")[0])\n",
    "        print \"Downloading: %s Bytes: %s\" % (file_name, file_size)\n",
    "\n",
    "        file_size_dl = 0\n",
    "        block_sz = 1024*1024\n",
    "        prior_percent = 0\n",
    "        while True:\n",
    "            buffer = u.read(block_sz)\n",
    "            if not buffer:\n",
    "                break\n",
    "            file_size_dl += len(buffer)\n",
    "            f.write(buffer)\n",
    "            status = r\"%10d  [%3.2f%%]\" % (file_size_dl, file_size_dl * 100. / file_size)\n",
    "            status = status + chr(8)*(len(status)+1)\n",
    "            if (file_size_dl * 100. / file_size) > (prior_percent+20):\n",
    "                print status + '\\n'\n",
    "                prior_percent = (file_size_dl * 100. / file_size)\n",
    "        f.close()\n",
    "\n",
    "def hello():\n",
    "    print(\"Is it me you're looking for?\")\n",
    "    return True\n",
    "\n",
    "\n",
    "#%% CLASSES\n",
    "class API(object):\n",
    "    # making a class out of the api() function, adding other methods\n",
    "    def __init__(self, path, method='GET', query=None, data=None, flagFullPath=False):\n",
    "        self.flag = {'longList': False}\n",
    "        response_dict = api_call(path, method, query, data, flagFullPath)\n",
    "        self.response_to_fields(response_dict)\n",
    "\n",
    "        if self.flag['longList']:\n",
    "            self.long_list(response_dict, path, method, query, data)\n",
    "\n",
    "    def response_to_fields(self,rd):\n",
    "        if 'items' in rd.keys():        # get * {files, projects, tasks, apps}              (object name plural)\n",
    "            if len(rd['items']) > 0:\n",
    "                self.list_read(rd)\n",
    "            else:\n",
    "                self.empty_read(rd)\n",
    "        else:                           # get details about ONE {file, project, task, app}  (object name singular)\n",
    "            self.detail_read(rd)\n",
    "\n",
    "    def list_read(self,rd):\n",
    "        n = len(rd['items'])\n",
    "        keys = rd['items'][0].keys()\n",
    "        m = len(keys)\n",
    "\n",
    "        for jj in range(m):\n",
    "            temp = [None]*n\n",
    "            for ii in range(n):\n",
    "                temp[ii] = rd['items'][ii][keys[jj]]\n",
    "            setattr(self, keys[jj], temp)\n",
    "\n",
    "        if ('links' in rd.keys()) & (len(rd['links']) > 0):\n",
    "            self.flag['longList'] = True\n",
    "\n",
    "    def empty_read(self,rd):    # in case an empty project is queried\n",
    "        self.href = []\n",
    "        self.id = []\n",
    "        self.name = []\n",
    "        self.project = []\n",
    "\n",
    "    def detail_read(self,rd):\n",
    "        keys = rd.keys()\n",
    "        m = len(keys)\n",
    "\n",
    "        for jj in range(m):\n",
    "            setattr(self, keys[jj], rd[keys[jj]])\n",
    "\n",
    "    def long_list(self, rd, path, method, query, data):\n",
    "        prior = rd['links'][0]['rel']\n",
    "        # Normally .rel[0] is the next, and .rel[1] is prior. If .rel[0] = prior, then you are at END_OF_LIST\n",
    "        keys = rd['items'][0].keys()\n",
    "        m = len(keys)\n",
    "\n",
    "        while prior == 'next':\n",
    "            rd = api_call(rd['links'][0]['href'], method, query, data, flagFullPath=True)\n",
    "            prior = rd['links'][0]['rel']\n",
    "            n = len(rd['items'])\n",
    "            for jj in range(m):\n",
    "                temp = getattr(self, keys[jj])          # possible speed bottleneck next three ops (allocating memory)\n",
    "                for ii in range(n):\n",
    "                    temp.append(rd['items'][ii][keys[jj]])\n",
    "                setattr(self, keys[jj], temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ != \"__main__\":\n",
    "    exit()              # prevent accidentally running script if loading file\n",
    "    \n",
    "# Did you remember to change the AUTH_TOKEN\n",
    "if AUTH_TOKEN == 'AUTH_TOKEN':\n",
    "    print \"You need to replace 'AUTH_TOKEN' string with your actual token. Please fix it.\"\n",
    "    exit() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a project\n",
    "Projects are the foundation of any analysis on the CGC. We can either use a project that has already been created, or we can use the API to create one. Here we will create a new project, but first check that it doesn't exist to show both methods. The *project name*, Pilot Fund *billing group*, and a project *description* will be sent in our API call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all billing groups on your account\n",
    "billingGroups = API('billing/groups')\n",
    "# Select the first billing group, this is \"Pilot_funds(USER_NAME)\"\n",
    "print billingGroups.name[0], \\\n",
    "'will be charged for this computation. Approximate price is $4 for example STAR RNA seq (n=1) \\n'\n",
    "\n",
    "# list all projects you are part of\n",
    "existingProjects = API(path='projects')                         # make sure your project doesn't already exist\n",
    "\n",
    "# set up the information for your new project\n",
    "NewProject = {\n",
    "        'billing_group': billingGroups.id[0],\n",
    "        'description': \"A project created by the API Quickstart\",\n",
    "        'name': TARGET_PROJECT,\n",
    "        'tags': ['tcga']\n",
    "}\n",
    "\n",
    "# Check to make sure your project doesn't already exist on the platform\n",
    "for ii,p_name in enumerate(existingProjects.name):\n",
    "    if TARGET_PROJECT == p_name:\n",
    "        FLAGS['targetFound'] = True\n",
    "        break\n",
    "\n",
    "# Make a shiny, new project\n",
    "if FLAGS['targetFound']:\n",
    "    myProject = API(path=('projects/' + existingProjects.id[ii]))    # GET existing project details (we need them later)\n",
    "else:\n",
    "    myProject = API(method='POST', data=NewProject, path='projects') # POST new project\n",
    "    # (re)list all projects, to check that new project posted\n",
    "    existingProjects = API(path='projects')\n",
    "    # GET new project details (we will need them later)\n",
    "    myProject = API(path=('projects/' + existingProjects.id[0]))    # GET new project details (we need them later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add files\n",
    "Here we have multiple options for adding data to a project, but will only present:\n",
    "* Copy files from existing project (API)\n",
    "\n",
    "Here we will take advantage of the already created Quickstart project from the GUI tutorial. This code will look for our three input files from that project and copy them over. \n",
    "\n",
    "Note: other options are available in docs (TODO: link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii,p_id in enumerate(existingProjects.id):\n",
    "    if existingProjects.name[ii] == 'QuickStart':\n",
    "        filesToCopy = API(('files?limit=100&project=' + p_id))\n",
    "        break\n",
    "\n",
    "# Don't make extra copies of files (loop through all files because we don't know what we want)\n",
    "myFiles = API(('files?limit=100&project=' + myProject.id))  # files currently in project\n",
    "for jj,f_name in enumerate(filesToCopy.name):\n",
    "    # Conditional is HARDCODED for RNA Seq STAR workflow\n",
    "    if f_name[-len(INPUT_EXT):] == INPUT_EXT or f_name[-len('sta'):] == 'sta' or \\\n",
    "                    f_name[-len('gtf'):] == 'gtf':\n",
    "        if f_name not in myFiles.name:                      # file currently not in project\n",
    "            api_call(path=(filesToCopy.href[jj] + '/actions/copy'), method='POST', \\\n",
    "                data={'project': myProject.id, 'name': f_name}, flagFullPath=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Applications or Workflows\n",
    "There are more than 150 public apps available on the Seven Bridges CGC. Here we query all of them, then copy the target workflow to our project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFiles = API(('files?limit=100&project=' + myProject.id))   # GET files LIST, regardless of upload method\n",
    "\n",
    "# Add workflow (copy from other project or GUI, not looping through all apps, we know exactly what we want)\n",
    "allApps = API(path='apps?limit=100&visibility=public')          # long function call, currently 183\n",
    "myApps = API(path=('apps?limit=100&project=' + myProject.id))\n",
    "if TARGET_APP not in allApps.name:\n",
    "    print \"Target app (%s) does not exist in the public repository. Please double-check the spelling\" % (TARGET_APP)\n",
    "else:\n",
    "    ii = allApps.name.index(TARGET_APP)\n",
    "    if TARGET_APP not in myApps.name:                           # app not already in project\n",
    "        temp_name = allApps.href[ii].split('/')[-2]             # copy app from public repository\n",
    "        api_call(path=('apps/' + allApps.project[ii] + '/' + temp_name + '/actions/copy'), \\\n",
    "            method='POST', data={'project': myProject.id, 'name': TARGET_APP})\n",
    "        myApps = API(path=('apps?limit=100&project=' + myProject.id))   # update project app list\n",
    "del allApps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a file processing list\n",
    "Most likely, we will only have one input file and two reference files in the project. However, if multiple input files were imported, this will create a batch of *single-input-single-output tasks* - one for each file. This code builds the list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build .fileProcessing (inputs) and .fileIndex (references) lists [for workflow]\n",
    "FileProcList = ['Files to Process']\n",
    "Ind_GtfFile = None\n",
    "Ind_FastaFile = None\n",
    "\n",
    "for ii,f_name in enumerate(myFiles.name):\n",
    "    # this conditional is for 'RNA seq STAR alignment' in Quickstart_API. _Adapt_ appropriately for other workflows\n",
    "    if f_name[-len(INPUT_EXT):] == INPUT_EXT:                                      # input file\n",
    "        FileProcList.append(ii)\n",
    "    elif f_name[-len('gtf'):] == 'gtf':\n",
    "        Ind_GtfFile = ii\n",
    "    elif f_name[-len('sta'):] == 'sta':\n",
    "        Ind_FastaFile = ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Start tasks\n",
    "Next we will iterate through the File Processing List (FileProcList) to generate one task for each input file. If the Flag *startTasks* is true, the tasks will start running immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myTaskList = [None]\n",
    "for ii,f_ind in enumerate(FileProcList[1:]):                    # Start at 1 because FileProcList[0] is a header\n",
    "    NewTask = {'description': 'APIs are awesome',\n",
    "        'name': ('batch_task_' +  str(ii)),\n",
    "        'app': (myApps.id[0]),                                  # ASSUMES only single workflow in project\n",
    "        'project': myProject.id,\n",
    "        'inputs': {\n",
    "            'genomeFastaFiles': {                               # .fasta reference file\n",
    "                'class': 'File',\n",
    "                'path': myFiles.id[Ind_FastaFile],\n",
    "                'name': myFiles.name[Ind_FastaFile]\n",
    "            },\n",
    "            'input_archive_file': {                             # File Processing List\n",
    "                'class': 'File',\n",
    "                'path': myFiles.id[f_ind],\n",
    "                'name': myFiles.name[f_ind]\n",
    "            },\n",
    "            # .gtf reference file, !NOTE: this workflow expects a _list_ for this input\n",
    "            'sjdbGTFfile': [\n",
    "               {\n",
    "                'class': 'File',\n",
    "                'path': myFiles.id[Ind_GtfFile],\n",
    "                'name': myFiles.name[Ind_GtfFile]\n",
    "               }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    # Create the tasks, run if FLAGS['startTasks']\n",
    "    if FLAGS['startTasks']:\n",
    "        myTask = api_call(method='POST', data=NewTask, path='tasks/', query={'action': 'run'})        # task created and run\n",
    "        myTaskList.append(myTask['href'])\n",
    "    else:\n",
    "        myTask = api_call(method='POST', data=NewTask, path='tasks/')        # task created and run\n",
    "myTaskList.pop(0)\n",
    "\n",
    "print \"%i tasks have been created. \\n\" % (ii+1)\n",
    "print \"Enjoy a break, come back to us once you've gotten an email that tasks are done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check task completion\n",
    "These tasks may take a long time to complete, here are two ways to check in on them:\n",
    "* Wait for email confirmation\n",
    "* No additional code need, emails will arrive whether the task was started by GUI or API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if tasks were started, check if they've finished\n",
    "for href in myTaskList:\n",
    "    # check on one task at a time, if any running, can not continue (no sense to query others)\n",
    "    print \"Pinging CGC for task completion, will download summary files once all tasks completed.\"\n",
    "    FLAGS['taskRunning'] = True\n",
    "    while FLAGS['taskRunning']:\n",
    "        task = api_call(path=href, flagFullPath=True)\n",
    "        if task['status'] == 'COMPLETED':\n",
    "            FLAGS['taskRunning'] = False\n",
    "        elif task['status'] == 'FAILED':                        # NOTE: also leaving loop on \"FAILED\" statuses\n",
    "            print \"Task failed, can not continue\"\n",
    "            exit()\n",
    "        timer.sleep(600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA CELLS \n",
    "From the Quickstart, these are the files for:\n",
    "* downloading files\n",
    "* uploading local files\n",
    "* setting file metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib2 import urlopen\n",
    "import os\n",
    " \n",
    "def download_files(fileList):\n",
    "    # download a list of files from URLs (adapted from a few stackoverflow threads)\n",
    "    dl_dir = 'downloads/'\n",
    "    try:                    # make sure we have the download directory\n",
    "        os.stat(dl_dir)\n",
    "    except:\n",
    "        os.mkdir(dl_dir)\n",
    " \n",
    "    for ii in range(1, len(fileList)):  # skip first [0] entry, it is a text header\n",
    "        url = fileList[ii]\n",
    "        file_name = url.split('/')[-1]\n",
    "        file_name = file_name.split('?')[0]\n",
    "        file_name = file_name.split('%2B')[1]\n",
    "        u = urlopen(url)\n",
    "        f = open((dl_dir + file_name), 'wb')\n",
    "        meta = u.info()\n",
    "        file_size = int(meta.getheaders(\"Content-Length\")[0])\n",
    "        print \"Downloading: %s Bytes: %s\" % (file_name, file_size)\n",
    " \n",
    "        file_size_dl = 0\n",
    "        block_sz = 1024*1024\n",
    "        prior_percent = 0\n",
    "        while True:\n",
    "            buffer = u.read(block_sz)\n",
    "            if not buffer:\n",
    "                break\n",
    "            file_size_dl += len(buffer)\n",
    "            f.write(buffer)\n",
    "            status = r\"%10d  [%3.2f%%]\" % (file_size_dl, file_size_dl * 100. / file_size)\n",
    "            status = status + chr(8)*(len(status)+1)\n",
    "            if (file_size_dl * 100. / file_size) > (prior_percent+20):\n",
    "                print status + '\\n'\n",
    "                prior_percent = (file_size_dl * 100. / file_size)\n",
    "        f.close()\n",
    "\n",
    "# Check which files have been generated (only taking small files to avoid long times)\n",
    "myNewFiles = API(('files?project=' + myProject.id))        # calling again to see what was generated\n",
    "dlList = [\"links to file downloads\"]\n",
    "\n",
    "for ii, f_name in enumerate(myNewFiles.name):\n",
    "    # downloading only the summary files. Adapt for whichever files you need\n",
    "    if (f_name[-4:] == '.out'):\n",
    "        dlList.append(api_call(path=('files/' + myNewFiles.id[ii] + '/download_info'))['url'])\n",
    "T0 = timer.time()\n",
    "download_files(dlList)\n",
    "print timer.time() - T0, \"seconds download time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: validate this\n",
    "\n",
    "print \"You need to install the command line uploader before proceeding\"\n",
    "ToUpload = ['G17498.TCGA-02-2483-01A-01R-1849-01.2.tar.gz','ucsc.hg19.fasta','human_hg19_genes_2014.gtf']\n",
    "for ii in range(len(ToUpload)):\n",
    "    cmds = \"cd ~/cgc-uploader; bin/cgc-uploader.sh -p 0f90eae7-2a76-4332-a233-6d20990189b7 \" + \\\n",
    "        \"/Users/digi/PycharmProjects/cgc_API/toUpload/\" + ToUpload[ii]   \n",
    "    os.system(cmds)    # TODO, uncomment\n",
    "del cmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFiles = API(('files?project=' + myProject.id))                       # GET files LIST\n",
    "\n",
    "metadata = {\n",
    "    \"name\": \"readme.md\",\n",
    "    \"library\":\"TEST\",\n",
    "    \"file_type\": \"fastq\",\n",
    "    \"sample\": \"example_human_Illumina\",\n",
    "    \"seq_tech\": \"Illumina\",\n",
    "    \"paired_end\": \"1\",\n",
    "    'gender': \"male\",\n",
    "    \"data_format\": \"awesome\"\n",
    "}\n",
    "print myFiles.href[3] + '/metadata'\n",
    "\n",
    "api_call(path=(myFiles.href[3] + '/metadata'), method='PUT', data = metadata, flagFullPath=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
